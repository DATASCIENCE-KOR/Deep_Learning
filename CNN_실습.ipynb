{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN ì‹¤ìŠµ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVwmcwbJj6Xw"
      },
      "source": [
        "## **ğŸ“Œ Tenserflowë¡œ ì‹¤ìŠµí•˜ëŠ” CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuWLWDMein8m"
      },
      "source": [
        "###  1. ê¸°ë³¸ ì„¤ì • â—"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_jxJln3gnBQ"
      },
      "source": [
        "> ë¶„ì„ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-R6HU3Zgv5P"
      },
      "source": [
        "import os \n",
        "import numpy as np \n",
        "import pandas as pd #csv íŒŒì¼ I/O\n",
        "import matplotlib.pyplot as plt #ì‹œê°í™”"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAdJ59Q3ERki"
      },
      "source": [
        "import tensorflow as tf #ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from os import getcwd\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_11jkNmUk0md"
      },
      "source": [
        "## 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ğŸ“‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0mlnJ0NlQ4Y"
      },
      "source": [
        "\n",
        "\n",
        "> ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1phSHL3hYD-"
      },
      "source": [
        "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ > MyDriveì— í´ë” ìƒì„± í›„ ë°ì´í„° ì§ì ‘ ì—…ë¡œë“œ\n",
        "# > ì½”ë© íŒŒì¼ì— ë“¤ì–´ì™€ì„œ ê²½ë¡œ ë³µì‚¬ í›„ train_dir, test_dirì— í• ë‹¹\n",
        "train_dir='/content/drive/MyDrive/zin/seg_train/seg_train'\n",
        "test_dir='/content/drive/MyDrive/zin/seg_test/seg_test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZnCHgMFHeYk"
      },
      "source": [
        "## 3. ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgbnUFl8E3Dx"
      },
      "source": [
        "> targetì´ ë¶„ë¥˜ë˜ì–´ ìˆëŠ” íŒŒì¼ì„ ìœ„í•œ label encoding\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk-Lyvl8hbB9",
        "outputId": "e88ef337-d58c-401f-f1bd-092a0de29525"
      },
      "source": [
        "# ë¶„ì„ì„ ìœ„í•œ ì´ë¯¸ì§€ í¬ê¸° ë° ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì„¤ì •\n",
        "\n",
        "IMG_SIZE = (150,150)\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=train_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    label_mode = \"categorical\", #label í˜•íƒœ ì„¤ì •\n",
        "    batch_size=64)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=test_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    label_mode = \"categorical\", #label í˜•íƒœ ì„¤ì •\n",
        "    batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14034 files belonging to 6 classes.\n",
            "Found 3000 files belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eorViN36iEYn",
        "outputId": "4ba16890-90f4-43d7-f5a0-15201fef1b95"
      },
      "source": [
        "# íƒ€ê²Ÿë³€ìˆ˜ í™•ì¸\n",
        "train_data.class_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flttDuSdYQ0X"
      },
      "source": [
        "# íƒ€ê²Ÿ ë²”ì£¼ :class_names x \n",
        "class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\n",
        "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
        "nb_classes = len(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucsKhVWKh3bV"
      },
      "source": [
        "# íŒŒì¼ë³„ë¡œ ë¶„ë¥˜ëœ ì´ë¯¸ì§€ ë¼ë²¨ë§ í•¨ìˆ˜\n",
        "def load_data():\n",
        "    train_test = ['seg_train/seg_train', 'seg_test/seg_test']\n",
        "    size = (150, 150)\n",
        "    output = [] \n",
        "    \n",
        "    for dataset in train_test:\n",
        "        directory = \"/content/drive/MyDrive/zin/\" + dataset\n",
        "        images = []\n",
        "        labels = []\n",
        "        print(\"Loading {}\".format(dataset))\n",
        "\n",
        "        for folder in os.listdir(directory):\n",
        "            label = class_names_label[folder]\n",
        "            for file in os.listdir(directory + \"/\" + folder):\n",
        "                img_path = directory + \"/\" + folder + \"/\" + file\n",
        "                curr_img = cv2.imread(img_path)\n",
        "                curr_img = cv2.resize(curr_img, size)\n",
        "                images.append(curr_img)\n",
        "                labels.append(label)\n",
        "        images = np.array(images, dtype='float32')\n",
        "        labels = np.array(labels, dtype='int32')\n",
        "\n",
        "        images = images / 255.0 #ë°ì´í„° ì •ê·œí™”\n",
        "\n",
        "        output.append((images, labels))\n",
        "\n",
        "    return output\n",
        "\n",
        "n_classes = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPncz6sJiSo-",
        "outputId": "1bb83f87-a551-4817-ec10-376d21f5825c"
      },
      "source": [
        "(train_images, train_labels),(test_images, test_labels) = load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading seg_train/seg_train\n",
            "Loading seg_test/seg_test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "bwN5JsYTHAfk",
        "outputId": "d240f29c-c28e-42ec-d735-9c81333e83e8"
      },
      "source": [
        "# train_image í˜•íƒœ\n",
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c219a107c28f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train_image í˜•íƒœ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKlTmOsUjWCh"
      },
      "source": [
        "# test_image í˜•íƒœ\n",
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "Wnoge6M9jeCA",
        "outputId": "d35372c5-8115-49ba-8323-1ec157cc0969"
      },
      "source": [
        "# ë°ì´í„° ì…‹ ì¤‘ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ í™•ì¸\n",
        "IMG_INDEX = 1126\n",
        "\n",
        "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
        "plt.xlabel(class_names[train_labels[IMG_INDEX]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-a08f2a3db1eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mIMG_INDEX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1126\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIMG_INDEX\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIMG_INDEX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4XpkwTyiIfg"
      },
      "source": [
        "# 3. CNN ì‹¤ìŠµ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNAavhP_lYIH"
      },
      "source": [
        "> CNN ëª¨ë¸ë§\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31dmbgaViHy1"
      },
      "source": [
        "# ëª¨ë¸ë§\n",
        "model_0 = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255), # ë°ì´í„° ì •ê·œí™”\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=IMG_SIZE+(3,)),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1_Zkg_UiVeo"
      },
      "source": [
        "# ëª¨ë¸ compile\n",
        "model_0.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnEn1tr8lfo2"
      },
      "source": [
        "\n",
        "\n",
        "> ëª¨ë¸ ì˜ˆì¸¡\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "PCKQGQbbnLnN",
        "outputId": "ef1d15e9-f9b9-4efc-b300-1401bb5f46fd"
      },
      "source": [
        "# ì˜ˆì¸¡\n",
        "history_0 = model_0.fit(train_data,\n",
        "                        epochs=10,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 66/220 [========>.....................] - ETA: 24:12 - loss: 1.3235 - accuracy: 0.4659"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-59a6f2d802e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                         validation_steps=len(test_data))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fKm2AIJnc4c"
      },
      "source": [
        "# ëª¨ë¸ ìš”ì•½ í™•ì¸\n",
        "model_0.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZxu8mwllWf"
      },
      "source": [
        "# 4. CNN ëª¨ë¸ í‰ê°€ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ6bTMQ-nk30"
      },
      "source": [
        "> ê·¸ë˜í”„ë¥¼ í†µí•´ loss ê°’ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktlm9YFjnkFD"
      },
      "source": [
        "def plot_loss_curves(history):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Epochì— ë”°ë¥¸ ì†ì‹¤ ì •ë„ í‘œë¡œ ë‚˜íƒ€ë‚´ê¸°\n",
        "  plt.plot(epochs, loss, label='training_loss') #train loss\n",
        "  plt.plot(epochs, val_loss, label='val_loss') #validation loss\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Epochì— ë”°ë¥¸ ì •í™•ë„ í‘œë¡œ ë‚˜íƒ€ë‚´ê¸°\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n",
        "    \n",
        "\n",
        "plot_loss_curves(history_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aij6N-pkC3q4"
      },
      "source": [
        "# Let's evaluate the model\n",
        "model_0.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abUf7daC0XvC"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='network_regression_model_shapes.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WZu1GeA0ce1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}